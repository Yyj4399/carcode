# MobileNet V2 分类模型训练说明

## 项目概述

本项目提供了一个完整的 MobileNet V2 分类模型训练脚本，支持自动检测类别数、Int8 量化输出、混淆矩阵可视化、交互式多轮训练，内存占用约 1000KB。

## 主要特性

- ✅ **自动检测类别数**：自动从数据集文件夹中检测分类类别
- ✅ **轻量级模型**：使用 Alpha=0.5 的 MobileNetV2，平衡性能与模型大小
- ✅ **Int8 量化**：输出 Int8 量化模型（非 uint8），大幅减小模型体积
- ✅ **无数据增强**：训练过程中不使用数据增强，仅进行归一化处理
- ✅ **混淆矩阵**：自动生成混淆矩阵可视化图和详细分类报告
- ✅ **交互式训练**：支持分阶段训练，每轮后可调整参数或停止训练
- ✅ **内存优化**：量化后模型大小约 1000KB

## 文件说明

- `train_mobilenetv2.py`：主训练脚本

## 数据集要求

### 目录结构

```
/mnt/num/
├── train/              # 训练集
│   ├── class_1/        # 类别1
│   │   ├── img1.jpg
│   │   ├── img2.jpg
│   │   └── ...
│   ├── class_2/        # 类别2
│   │   └── ...
│   └── class_n/        # 类别n
│       └── ...
└── test/               # 测试集
    ├── class_1/
    ├── class_2/
    └── class_n/
```

## 配置参数

### 可调节参数（在 Config 类中）

| 参数 | 默认值 | 说明 | 可选值 |
|------|--------|------|--------|
| `ALPHA` | 0.5 | MobileNetV2 宽度乘数 | 0.35, 0.5, 0.75, 1.0 |
| `INPUT_SHAPE` | (128, 128, 3) | 输入图像尺寸 | 任意尺寸，建议 96-224 |
| `BATCH_SIZE` | 32 | 批次大小 | 根据内存调整 |
| `EPOCHS` | 50 | 总训练轮数（参考值） | 根据需要调整 |
| `EPOCHS_PER_ROUND` | 10 | 每轮训练的epoch数 | 建议 5-20 |
| `LEARNING_RATE` | 0.001 | 初始学习率 | 0.0001-0.01 |

### 数据集路径

```python
TRAIN_DIR = '/mnt/num/train'  # 训练集路径
TEST_DIR = '/mnt/num/test'    # 测试集路径
```

## 使用方法

### 1. 安装依赖

```bash
pip install tensorflow numpy matplotlib seaborn scikit-learn
```

依赖库说明：
- `tensorflow`：模型训练和转换
- `numpy`：数值计算
- `matplotlib`：混淆矩阵可视化
- `seaborn`：美化混淆矩阵图表
- `scikit-learn`：生成混淆矩阵和分类报告

### 2. 准备数据集

确保数据集按照上述目录结构组织，脚本会自动检测类别数。

### 3. 运行训练

详细的使用示例和参数说明请参见下方的"命令行参数"和"使用示例"部分。

```bash
# 快速开始（使用默认参数）
python train_mobilenetv2.py

# 查看所有命令行参数
python train_mobilenetv2.py --help
```

#### 命令行参数

| 参数 | 类型 | 默认值 | 说明 |
|------|------|--------|------|
| `--epoch` | int | 10 | 首轮训练的epoch数 |
| `--lr` | float | 0.001 | 初始学习率 |
| `--batch_size` | int | 32 | 批次大小 |
| `--alpha` | float | 0.5 | MobileNetV2的宽度乘数 (0.35, 0.5, 0.75, 1.0) |
| `--input_size` | int | 128 | 输入图像尺寸 (例如: 64, 96, 128, 224) |
| `--augmentation` | flag | False | 启用数据增强 (默认: 关闭) |
| `--continue_epochs` | int | None | 继续训练时的epoch数 (仅在--auto_continue模式下生效) |
| `--continue_lr` | float | None | 继续训练时的学习率 (仅在--auto_continue模式下生效) |
| `--continue_batch_size` | int | None | 继续训练时的批次大小 (仅在--auto_continue模式下生效) |
| `--continue_augmentation` | int | None | 继续训练时是否启用数据增强 (0=关闭, 1=开启, 仅在--auto_continue模式下生效) |
| `--auto_continue` | flag | False | 启用自动继续训练模式 (不询问是否继续) |

#### 使用示例

##### 基本训练（交互式模式）
```bash
# 使用默认参数（每轮都会询问）
python train_mobilenetv2.py

# 自定义首轮训练参数（后续轮次通过交互设置）
python train_mobilenetv2.py --epoch 20 --lr 0.001 --batch_size 16

# 启用数据增强进行训练
python train_mobilenetv2.py --epoch 20 --augmentation

# 使用较小的批次大小和数据增强
python train_mobilenetv2.py --batch_size 8 --augmentation
```

##### 完全自动训练模式（推荐用于批处理）
```bash
# 自动继续训练，不询问用户
python train_mobilenetv2.py --epoch 20 --continue_epochs 10 --continue_lr 0.0005 --auto_continue

# 说明：
# - 首轮训练20个epoch，学习率为0.001（默认）
# - 自动继续训练10个epoch，学习率降为0.0005
# - 不会询问任何问题
# - 训练完成后停止（只会继续一轮）

# 自动训练并在继续时启用数据增强
python train_mobilenetv2.py --epoch 20 --continue_epochs 10 --continue_augmentation 1 --auto_continue

# 自动训练并在继续时调整batch_size
python train_mobilenetv2.py --batch_size 32 --epoch 20 --continue_epochs 10 --continue_batch_size 16 --auto_continue

# 完整示例：首轮大batch_size无增强，第二轮小batch_size有增强
python train_mobilenetv2.py --batch_size 32 --epoch 20 --continue_epochs 10 --continue_batch_size 16 --continue_augmentation 1 --auto_continue
```

##### 自定义模型参数
```bash
# 使用更小的模型（减小内存占用）
python train_mobilenetv2.py --alpha 0.35 --input_size 64 --batch_size 16

# 使用更大的模型（提高准确率）
python train_mobilenetv2.py --alpha 0.75 --input_size 224 --batch_size 8
```

##### 完整示例：多阶段自动训练
```bash
# 第一阶段：大学习率快速训练
python train_mobilenetv2.py --epoch 20 --lr 0.001 --continue_epochs 15 --continue_lr 0.0005 --auto_continue

# 训练完成后，如果需要继续精细调优，可以再次运行：
# 第二阶段：小学习率精细调优
python train_mobilenetv2.py --epoch 10 --lr 0.0001 --continue_epochs 5 --continue_lr 0.00005 --auto_continue
```

**重要说明**：
- `--continue_epochs`、`--continue_lr`、`--continue_batch_size`、`--continue_augmentation` **仅在 `--auto_continue` 模式下生效**
- 在交互式模式下（不使用 `--auto_continue`），这些参数会被忽略，完全通过交互来控制
- 如果使用 `--auto_continue` 但没有指定 `--continue_epochs`，程序会在首轮训练后停止

### 4. 训练过程

脚本会依次执行以下步骤：

1. **检测数据集类别**：自动识别训练集中的所有类别
2. **加载数据集**：从指定路径加载训练和测试数据
3. **构建模型**：创建 MobileNetV2 模型（Alpha=0.5）
4. **交互式训练**：分阶段训练模型
   - 每轮训练指定数量的 epoch（默认 10 个）
   - 训练完每轮后显示本轮结果
   - 询问是否继续训练
   - 如果继续，可以选择调整学习率和每轮训练轮数
   - 重复直到用户选择停止
5. **显示训练摘要**：汇总所有训练阶段的结果
6. **加载最佳模型**：从检查点加载验证准确率最高的模型
7. **评估模型**：在测试集上评估最终性能
8. **生成混淆矩阵**：生成混淆矩阵图像和详细分类报告
9. **保存最终模型**：保存完整的 Keras 模型
10. **Int8 量化**：将模型转换为 Int8 量化的 TFLite 格式

### 5. 训练模式说明

脚本支持两种训练模式：

#### 模式1：交互式模式（默认）

**使用场景**：适合实验性训练，需要根据训练效果动态调整参数

**特点**：
- 每轮训练后询问是否继续
- 如果继续，询问下一轮的参数：
  - epoch数
  - 学习率
  - 批次大小（batch_size）
  - 数据增强开关
- 完全手动控制训练流程
- **忽略 `--continue_epochs` 和 `--continue_lr` 参数**
- 当批次大小或数据增强设置改变时，自动重新加载数据集

**命令**：
```bash
python train_mobilenetv2.py --epoch 15
```

**流程**：
```
首轮训练15个epoch
  ↓
是否继续训练？(y/n): y
  ↓
输入本轮要训练的epoch数: 10
  ↓
是否调整学习率？(y/n): y
输入新的学习率: 0.0005
  ↓
是否调整批次大小？(y/n): y
输入新的批次大小: 16
  ↓
是否开启数据增强？(y/n): y
  ↓
检测到批次大小或数据增强设置改变，重新加载数据...
  ↓
训练10个epoch
  ↓
是否继续训练？(y/n): n
  ↓
训练结束
```

#### 模式2：完全自动模式

**使用场景**：用于批量训练或自动化流程，无需人工干预

**特点**：
- 不询问任何问题
- 完全按照命令行参数执行
- 适合脚本化和批处理
- **必须使用 `--auto_continue` 标志**

**命令**：
```bash
python train_mobilenetv2.py --epoch 20 --continue_epochs 10 --continue_lr 0.0005 --auto_continue
```

**流程**：
```
首轮训练20个epoch
  ↓
【自动继续训练模式】
使用命令行参数继续训练
下一轮学习率: 0.0005
下一轮训练轮数: 10
  ↓
训练10个epoch
  ↓
【自动继续训练模式】
未指定更多--continue_epochs参数，训练已停止
  ↓
训练结束
```

**重要提示**：
- 自动模式只会继续一轮训练（使用 `--continue_epochs` 指定的轮数）
- 如果需要多轮训练，需要多次运行脚本
- 在交互式模式下，`--continue_epochs` 和 `--continue_lr` 参数会被忽略

### 6. 数据增强功能

#### 什么是数据增强？

数据增强是一种通过对训练图像进行随机变换来扩充训练数据的技术，可以有效防止过拟合并提高模型泛化能力。

#### 支持的数据增强操作

本脚本的数据增强包括以下操作：
- **旋转**：随机旋转图像 ±20°
- **平移**：水平和垂直方向随机平移 20%
- **水平翻转**：随机水平翻转图像
- **缩放**：随机缩放图像 20%
- **填充模式**：使用最近邻填充

#### 何时使用数据增强？

**建议开启数据增强的情况**：
- 训练数据较少（每个类别少于1000张图片）
- 出现过拟合（训练准确率远高于验证准确率）
- 希望提高模型的泛化能力

**建议关闭数据增强的情况**：
- 训练数据充足且均衡
- 数据本身已经包含足够的多样性
- 训练速度要求高（数据增强会增加训练时间）

#### 在交互式训练中使用数据增强

在训练中断询问参数时，可以选择开启或关闭数据增强：

```
是否继续训练？(y/n): y

输入本轮要训练的epoch数: 10

当前学习率: 0.001
是否调整学习率？(y/n): n

当前批次大小: 32
是否调整批次大小？(y/n): n

当前数据增强: 未开启
是否开启数据增强？(y/n): y

检测到批次大小或数据增强设置改变，重新加载数据...
使用数据增强
Found 1000 images belonging to 10 classes.
Found 200 images belonging to 10 classes.

本轮训练设置:
  训练轮数: 10
  学习率: 0.001
  批次大小: 32
  数据增强: 开启
```

#### 数据增强的影响

**优点**：
- 有效防止过拟合
- 提高模型的泛化能力
- 增加训练数据的多样性

**缺点**：
- 增加训练时间（每个epoch耗时约增加20-30%）
- 可能降低训练准确率（但通常会提高验证准确率）

**推荐使用策略**：
1. **初期训练**：关闭数据增强，快速收敛
2. **中期训练**：如果出现过拟合，开启数据增强
3. **后期微调**：根据验证准确率决定是否使用数据增强

### 7. 交互式训练示例

训练过程中的交互示例：

```bash
# 首次运行，训练15轮
$ python train_mobilenetv2.py --epoch 15
```

```
============================================================
MobileNet V2 分类模型训练 (交互式)
============================================================

[4] 开始交互式训练...
    - 初始学习率: 0.001
    - 首轮训练epoch数: 15

============================================================
【第 1 轮训练】
============================================================

  当前学习率: 0.001
  本轮训练轮数: 15

Epoch 1/15
[训练过程...]
Epoch 15/15
[训练完成]

  本轮训练结果:
    训练准确率: 0.8523, 验证准确率: 0.8234
    训练损失: 0.4123, 验证损失: 0.4567

============================================================
【训练暂停】
============================================================

是否继续训练？(y/n): y

------------------------------------------------------------
【继续训练参数设置】
------------------------------------------------------------

输入本轮要训练的epoch数 (例如: 10): 10

  当前学习率: 0.001
是否调整学习率？(y/n): y
输入新的学习率 (当前: 0.001): 0.0005

  本轮训练设置:
    训练轮数: 10
    学习率: 0.0005

============================================================
【第 2 轮训练】
============================================================

  当前学习率: 0.0005
  本轮训练轮数: 10

Epoch 1/10
[训练过程...]
Epoch 10/10
[训练完成]

  本轮训练结果:
    训练准确率: 0.9012, 验证准确率: 0.8956
    训练损失: 0.2876, 验证损失: 0.3234

============================================================
【训练暂停】
============================================================

是否继续训练？(y/n): n

  训练已停止
```

## 输出文件

训练完成后会生成以下文件：

| 文件名 | 说明 | 大小 |
|--------|------|------|
| `mobilenetv2_model.h5` | Keras 格式的完整模型（浮点型） | ~8MB |
| `mobilenetv2_int8.tflite` | Int8 量化的 TFLite 模型 | ~1MB |
| `confusion_matrix.png` | 混淆矩阵可视化图像（高分辨率） | ~100KB |
| `classification_report.txt` | 详细的分类报告文本 | ~2KB |
| `mobilenetv2_checkpoint.h5` | 训练过程中的最佳模型检查点 | ~8MB |

## 交互式训练功能

### 功能说明

交互式训练允许您在训练过程中灵活控制训练流程，而不是一次性训练固定的轮数。这种方式有以下优势：

1. **随时监控**：每轮训练后可以查看结果，决定是否继续
2. **灵活调整**：根据训练效果实时调整学习率和训练轮数
3. **节省时间**：当模型表现满意时可以提前停止
4. **参数优化**：可以在训练过程中尝试不同的学习率

### 工作流程

1. **启动训练**：通过命令行参数指定首轮训练的epoch数
   ```bash
   python train_mobilenetv2.py --epoch 15
   ```
2. **查看结果**：训练完成后显示本轮的训练和验证准确率/损失
3. **决策点 1 - 是否继续**：
   - 输入 `y` 继续训练
   - 输入 `n` 停止训练，进入模型评估和保存阶段
4. **决策点 2 - 设置下一轮参数**（仅在选择继续时）：
   - **必须输入**：下一轮要训练的epoch数（例如：10）
   - **可选调整**：是否修改学习率
5. **继续训练**：使用新参数开始下一轮训练
6. **重复**：回到步骤 2，直到选择停止

### 使用场景

#### 场景 1：快速验证

```bash
$ python train_mobilenetv2.py --epoch 10
```

```
第 1 轮训练 10 个 epoch → 验证准确率 0.95 → 停止训练
总耗时：约 10 分钟
```

适合：快速验证模型效果，发现模型很快收敛

#### 场景 2：分阶段降低学习率

```bash
$ python train_mobilenetv2.py --epoch 15 --lr 0.001
```

```
第 1 轮：15 epoch，学习率 0.001 → 验证准确率 0.85
  ↓ 继续，输入 10 epoch，调整学习率为 0.0005
第 2 轮：10 epoch，学习率 0.0005 → 验证准确率 0.90
  ↓ 继续，输入 10 epoch，调整学习率为 0.0001
第 3 轮：10 epoch，学习率 0.0001 → 验证准确率 0.92
  ↓ 停止训练
总耗时：约 35 分钟，共 35 个 epoch
```

适合：逐步降低学习率以获得更好的收敛效果

#### 场景 3：过拟合检测

```bash
$ python train_mobilenetv2.py --epoch 10
```

```
第 1 轮：10 epoch → 训练 0.88，验证 0.85
  ↓ 继续，输入 10 epoch
第 2 轮：10 epoch → 训练 0.92，验证 0.84
  ↓ 发现过拟合，停止训练
总耗时：约 20 分钟，共 20 个 epoch
```

适合：监控过拟合，及时停止避免浪费时间

#### 场景 4：灵活调整训练轮数

```bash
$ python train_mobilenetv2.py --epoch 20
```

```
第 1 轮：20 epoch → 验证准确率 0.87
  ↓ 继续，输入 5 epoch（小步调整）
第 2 轮：5 epoch → 验证准确率 0.89
  ↓ 继续，输入 5 epoch
第 3 轮：5 epoch → 验证准确率 0.90
  ↓ 停止训练
总耗时：约 30 分钟，共 30 个 epoch
```

适合：后期精细调优，每次训练少量epoch密切观察

### 参数调整建议

#### 学习率调整

| 阶段 | 建议学习率 | 说明 |
|------|-----------|------|
| 初期 | 0.001 | 快速收敛 |
| 中期 | 0.0005 | 细微调整 |
| 后期 | 0.0001 | 精细优化 |

#### 每轮训练轮数建议

| 阶段 | 建议轮数 | 说明 |
|------|---------|------|
| 初期探索 | 10-20 | 快速了解模型收敛情况 |
| 中期训练 | 10-15 | 稳定提升性能 |
| 精细调优 | 5-10 | 小步调整，密切监控 |
| 最后冲刺 | 3-5 | 极度精细的优化 |

**使用技巧：**
- 首次运行建议使用较大的轮数（如15-20），快速看到效果
- 后续训练可以减少轮数（如5-10），更灵活地控制训练过程
- 发现验证准确率波动时，减少轮数以便及时调整

### 训练历史摘要

训练结束后，会自动显示所有训练阶段的汇总信息：

```
============================================================
【训练历史摘要】
============================================================
  总训练轮数: 30
  训练阶段数: 3

  最佳验证准确率: 0.9234 (第 28 轮)

  各阶段训练结果:
    阶段 1 (Epoch 1-10):
      训练准确率: 0.8523, 验证准确率: 0.8234
      训练损失: 0.4123, 验证损失: 0.4567
    阶段 2 (Epoch 11-20):
      训练准确率: 0.9012, 验证准确率: 0.8956
      训练损失: 0.2876, 验证损失: 0.3234
    阶段 3 (Epoch 21-30):
      训练准确率: 0.9345, 验证准确率: 0.9234
      训练损失: 0.1923, 验证损失: 0.2456
============================================================
```

### 最佳实践

1. **首次运行用较大epoch数**：建议使用 `--epoch 15` 或 `--epoch 20`，快速了解模型收敛情况
2. **根据训练效果决定下一步**：
   - 损失快速下降 → 继续当前学习率，可以再训练相同轮数
   - 损失下降缓慢 → 降低学习率，减少轮数（如5-10）
   - 验证损失上升 → 停止训练（过拟合）
3. **灵活调整训练轮数**：
   - 中期：使用10-15轮稳定提升
   - 后期：使用5-10轮精细调优
   - 最后：使用3-5轮微调
4. **保存检查点**：每轮训练都会自动保存最佳模型，不用担心丢失
5. **及时停止**：发现验证准确率不再提升或开始下降时及时停止

**典型训练策略：**
```bash
# 第1轮：快速探索（15-20 epoch）
python train_mobilenetv2.py --epoch 20

# 继续训练
是否继续？ y
输入本轮epoch数: 10
是否调整学习率？ n

# 继续训练并降低学习率
是否继续？ y
输入本轮epoch数: 10
是否调整学习率？ y
输入新的学习率: 0.0005

# 精细调优
是否继续？ y
输入本轮epoch数: 5
是否调整学习率？ y
输入新的学习率: 0.0001

# 停止训练
是否继续？ n
```

## 混淆矩阵功能

### 混淆矩阵说明

混淆矩阵是评估分类模型性能的重要工具，它展示了：
- **对角线元素**：正确分类的样本数量
- **非对角线元素**：错误分类的样本数量

### 混淆矩阵输出

训练完成后，会自动生成：

1. **可视化图像** (`confusion_matrix.png`)：
   - 热力图格式，颜色深浅表示样本数量
   - 行表示真实标签，列表示预测标签
   - 300 DPI 高分辨率，适合论文使用

2. **控制台输出**：
   - 数值形式的混淆矩阵
   - 各类别准确率统计
   - Precision、Recall、F1-Score 等指标

3. **分类报告文件** (`classification_report.txt`)：
   - 完整的混淆矩阵数据
   - 各类别详细统计
   - Precision、Recall、F1-Score
   - 宏平均和加权平均指标

### 混淆矩阵示例

```
真实\预测 |  class_1  |  class_2  |  class_3  |  class_4  |  class_5
----------------------------------------------------------------
 class_1   |    45     |     2     |     1     |     0     |     2
 class_2   |     1     |    48     |     0     |     1     |     0
 class_3   |     0     |     1     |    47     |     2     |     0
 class_4   |     0     |     0     |     1     |    49     |     0
 class_5   |     1     |     0     |     0     |     0     |    49
```

### 如何解读混淆矩阵

- **准确率高**：对角线数值大，非对角线数值小
- **混淆类别**：非对角线较大值表示容易混淆的类别对
- **改进方向**：针对混淆的类别增加训练样本或特征工程

## 模型量化细节

### Int8 量化配置

```python
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.inference_input_type = tf.int8
converter.inference_output_type = tf.int8
```

- **量化类型**：Int8（有符号 8 位整数）
- **量化范围**：-128 到 127
- **校准数据**：使用 100 个训练样本进行量化校准
- **内存占用**：约 1000KB（取决于类别数）

## 训练优化策略

脚本包含以下训练优化策略：

1. **模型检查点**：自动保存验证准确率最高的模型
2. **早停策略**：验证损失连续 10 轮不下降则停止训练
3. **学习率衰减**：验证损失连续 5 轮不下降则降低学习率

## 调整模型大小

如果量化后的模型超过 1000KB，可以尝试：

1. **降低 Alpha 值**：从 0.5 降至 0.35
2. **减小输入尺寸**：从 128x128 降至 96x96 或 64x64
3. **减少类别数**：合并或删除某些类别

示例配置（更小的模型）：

```python
ALPHA = 0.35
INPUT_SHAPE = (64, 64, 3)
```

## 性能预期

| 配置 | 模型大小 | 推理速度 | 准确率 |
|------|----------|----------|--------|
| Alpha=0.35, 64x64 | ~600KB | 快 | 中等 |
| Alpha=0.5, 128x128 | ~1200KB | 中等 | 较好 |
| Alpha=0.75, 128x128 | ~2000KB | 慢 | 好 |

## 注意事项

1. **预训练权重**：首次运行时会自动下载 ImageNet 预训练权重
2. **GPU 支持**：如果有 GPU，TensorFlow 会自动使用
3. **内存不足**：如果内存不足，可以减小 `BATCH_SIZE`
4. **类别平衡**：确保各类别样本数量相对均衡
5. **中文显示**：混淆矩阵如果类别名包含中文，需要系统支持中文字体

## 故障排除

### 问题 1：数据集路径不存在

```
ValueError: 数据集路径不存在: /mnt/num/train
```

**解决方法**：检查数据集路径是否正确，或修改 `Config` 类中的路径。

### 问题 2：内存溢出

```
ResourceExhaustedError: OOM when allocating tensor
```

**解决方法**：
- 减小 `BATCH_SIZE`（如 16 或 8）
- 减小 `INPUT_SHAPE`（如 (64, 64, 3)）

### 问题 3：量化模型过大

**解决方法**：
- 降低 `ALPHA` 值
- 减小输入图像尺寸
- 检查类别数是否过多

### 问题 4：混淆矩阵图像无法保存

```
FileNotFoundError: [Errno 2] No such file or directory
```

**解决方法**：
- 确保当前目录有写入权限
- 检查磁盘空间是否充足

### 问题 5：缺少依赖库

```
ModuleNotFoundError: No module named 'seaborn'
```

**解决方法**：
```bash
pip install matplotlib seaborn scikit-learn
```

## 推理示例

使用量化后的模型进行推理：

```python
import numpy as np
import tensorflow as tf
from PIL import Image

# 加载 TFLite 模型
interpreter = tf.lite.Interpreter(model_path='mobilenetv2_int8.tflite')
interpreter.allocate_tensors()

# 获取输入输出张量
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

# 加载并预处理图像
img = Image.open('test.jpg').resize((128, 128))
img_array = np.array(img, dtype=np.float32) / 255.0

# 量化输入（转换为 int8）
input_scale, input_zero_point = input_details[0]['quantization']
img_quantized = (img_array / input_scale + input_zero_point).astype(np.int8)

# 推理
interpreter.set_tensor(input_details[0]['index'], [img_quantized])
interpreter.invoke()

# 获取输出（int8）
output = interpreter.get_tensor(output_details[0]['index'])[0]

# 反量化输出
output_scale, output_zero_point = output_details[0]['quantization']
output_float = (output.astype(np.float32) - output_zero_point) * output_scale

# 获取预测类别
predicted_class = np.argmax(output_float)
print(f"预测类别: {predicted_class}")
```

## 更新日志

- **2025-10-20**：v1.7
  - **新增功能**：添加 `--augmentation` 命令行参数，支持在训练开始时通过命令行启用数据增强
  - **新增功能**：添加 `--continue_batch_size` 参数，支持在自动模式下继续训练时调整批次大小
  - **新增功能**：添加 `--continue_augmentation` 参数，支持在自动模式下继续训练时开启/关闭数据增强
  - 自动模式现在完全支持所有训练参数的动态调整（学习率、批次大小、数据增强）
  - 更新文档，添加完整的命令行参数使用示例
  - 改进自动继续训练逻辑，当批次大小或数据增强设置改变时自动重新加载数据

- **2025-10-20**：v1.6
  - **新增功能**：在交互式训练中支持动态调整批次大小（batch_size）
  - **新增功能**：在交互式训练中支持开启/关闭数据增强
  - 修改 `ask_next_training_parameters` 函数，增加batch_size和数据增强的询问
  - 修改 `load_data` 函数，支持数据增强参数
  - 当批次大小或数据增强设置改变时，自动重新加载数据集
  - 添加详细的数据增强功能说明文档
  - 数据增强包括：旋转、平移、水平翻转、缩放等操作

- **2025-10-20**：v1.5
  - 简化训练模式，从三种模式改为两种清晰的模式
  - **交互式模式**：完全通过交互控制，忽略 `--continue_epochs` 和 `--continue_lr`
  - **自动模式**：需要 `--auto_continue` 标志，完全不询问
  - 修复用户体验问题：交互式模式下不再提前设定继续训练参数
  - 更新文档，移除容易混淆的"半自动模式"说明

- **2025-10-20**：v1.4
  - 添加更多命令行参数：`--batch_size`、`--alpha`、`--input_size`
  - 添加继续训练参数：`--continue_epochs`、`--continue_lr`
  - 添加自动继续训练模式：`--auto_continue`
  - 支持三种训练模式：
    - 完全交互式：每轮训练后询问是否继续并询问参数
    - 半自动模式：每轮训练后询问是否继续，但使用命令行参数而不询问参数
    - 完全自动模式：不询问，直接使用命令行参数自动继续训练
  - 更新文档，添加详细的使用示例

- **2025-10-20**：v1.3
  - 添加命令行参数支持（`--epoch` 和 `--lr`）
  - 改进交互式训练流程，每轮后必须输入下一轮的epoch数
  - 简化参数调整逻辑，学习率调整改为可选
  - 更新使用示例和最佳实践指南

- **2025-10-20**：v1.2
  - 添加交互式训练功能
  - 支持分阶段训练，每轮后可选择继续或停止
  - 支持训练过程中动态调整学习率和训练轮数
  - 添加训练历史摘要功能
  - 添加训练检查点自动保存

- **2025-10-20**：v1.1
  - 添加混淆矩阵生成功能
  - 添加详细分类报告输出
  - 添加 matplotlib、seaborn、scikit-learn 依赖

- **2025-10-19**：v1.0
  - 创建 MobileNetV2 训练脚本
  - 实现自动类别检测
  - 实现 Int8 量化输出
  - 优化内存占用至约 1000KB

## 联系与反馈

如有问题或建议，请通过 Issues 反馈。
